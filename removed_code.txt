

trial_window = training_windows[0]
normalized_trial_window =normalizer.normalize_window(trial_window)








    # def test_GNN_output_above_ground(self):
    #     output = self.GNN_model(self.trial_window)
    #     min_elev = self.trial_window['norm_elev']
    #     all_heads_are_above_ground = torch.all(torch.ge(output, min_elev))
        
    #     self.assertTrue(all_heads_are_above_ground.item())
        
    # def test_vector_says_if_dry_or_not(self):
    #     output = self.GNN_model(self.trial_window)
    #     # min_elev = self.trial_window['norm_elev']
    #     some_node_is_dry = torch.all(output)
        
    #     self.assertTrue(some_node_is_dry.item())

    # def test_vector_there_should_be_flow_to(self):
    #     output = self.GNN_model(self.trial_window)
    #     print(output)
    #     someflow = torch.any(output)
    #     self.assertTrue(someflow.item())
        
        
    # def test_vector_is_min_or_20(self):
    #     output = self.GNN_model(self.trial_window)
    #     print(output.shape)
    #     for i in output:
    #         val = i.item()
    #         self.assertTrue((val==0.0 or val == 1.0))
        


# def test_GNN_has_trainable_parameters(self):
#     self.assertGreater(utils.count_parameters(self.GNN_model), 0)





# def normalize_min_max(value, max,min):
#     return (value - min)/(max-min)



# class Normalizer:
#     def __init__(self, X_train, y_train):
#         self.initial_heads = [i[1] for i in X_train]
#         self.y_train = y_train
#         self.max_h, self.min_h = self.get_max_and_min_h()
#         self.normalized_h0_in_x = self.normalize_x_heads()
#         self.normalized_ht_in_y = self.normalize_y_heads()

#     def get_max_and_min_h(self):
#         samples_final = []
#         samples_final.extend(self.initial_heads)
        
#         for i in self.y_train:
#             samples_final+=i
        
#         max = np.array(list(samples_final[0].values())).max()
#         min = np.array(list(samples_final[0].values())).min()

#         for sample in samples_final:
#             val_max = np.array(list(sample.values())).max()
#             val_min = np.array(list(sample.values())).min()
#             if val_max>max:
#                 max = val_max
#             if val_min<min:
#                 min = val_min

#         return max, min

#     def normalize_x_heads(self):       
#         normalized_samples = []
#         for sample in self.initial_heads:
#             normalized_sample = dict(map(lambda x: (x[0], normalize_min_max(x[1], self.max_h, self.min_h )), sample.items()))
#             normalized_samples.append(normalized_sample)
#         return normalized_samples


#     def normalize_y_heads(self):
#         normalized_list = []
#         for heads_in_step in self.y_train:
#             normalized_samples = []
#             for sample in heads_in_step:
#                 normalized_sample = dict(map(lambda x: (x[0], normalize_min_max(x[1], self.max_h, self.min_h )), sample.items()))
#                 normalized_samples.append(normalized_sample)
#             normalized_list.append(normalized_samples)
#         return normalized_list











self.node_names = nx.get_node_attributes(self.G, 'nodes_names')






 # for i in range(len(heads)-steps_ahead):

        #     h0_samples = heads.iloc[i,:].to_dict()
            
        #     ro_samples = [runoff.iloc[i].to_dict()]
        #     ht_samples = []
            
        #     for j in range(steps_ahead):    
        #         ht = heads.iloc[i+j+1,:].to_dict()
        #         ht_samples.append(ht)
                                
        #         ro = runoff.iloc[i+j+1].to_dict()
        #         ro_samples.append(ro)

        #     x0_samples = [h0_samples, ro_samples]

        #     couple=(x0_samples, ht_samples)
        #     couples.append(couple)

        # return couples





#SWMMEmulator----------------------------------------------------------------
# import torch
# import networkx as nx
# from utils.SWMM_Simulation import SWMMSimulation
# import utils.head_change_utils as utils

# class SWMMEmulator:
#     def __init__(self, inp_path):
#         self.inp_lines = utils.get_lines_from_textfile(inp_path)
#         self.G = utils.inp_to_G(self.inp_lines)
        
#         self.original_min =     convert_dict_values_to_torch( nx.get_node_attributes(self.G, 'elevation') )
#         self.original_A_catch = convert_dict_values_to_torch( nx.get_node_attributes(self.G, 'area_subcatchment') )
#         self.pos = nx.get_node_attributes(self.G, 'pos')

#     def create_simulation(self, rainfall_raw_data, heads_raw_data, runoff_raw_data):
#         simulation = SWMMSimulation(rainfall_raw_data, heads_raw_data, runoff_raw_data)
#         return(simulation)
    


# def to_torch(object_to_convert):
#     return torch.tensor(float(object_to_convert), dtype=torch.float32)

# def convert_dict_values_to_torch(d):
#     dict_torch = {k:to_torch(v) for k,v in d.items()}
#     return dict_torch
#----------------------------------------------------------------







# def q_interchange_in(dh, L, d):
#     """
#     This function evaluates the magnitude that the difference in head has in the next head. How water flows.
#     """

#     num = (d**(5/2))*(dh**0.5) #**2.0)
#     den = L**0.5
#     q = w_in*(num/den)
    
#     return q


# def q_interchange_out(dh, L, d):
#     """
#     This function evaluates the magnitude that the difference in head has in the next head. How water flows.
#     """

#     num = (d**(5/2))*(dh**0.5) #**2.0)
#     den = L**0.5
#     q = w_out*(num/den)
    
#     return -q